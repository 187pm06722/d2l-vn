<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>Introduction &#8212; Đắm mình vào Học Sâu 0.7.0 documentation</title>

    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/d2l.css" />
    <link rel="stylesheet" href="../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../_static/fonts.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script type="text/javascript" src="../_static/d2l.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
  </head>
<body>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link is-active">Introduction</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
<a id="button-show-source"
    class="mdl-button mdl-js-button mdl-button--icon"
    href="../_sources/chapter_introduction/intro.rst.txt" rel="nofollow">
  <i class="material-icons">code</i>
</a>
<div class="mdl-tooltip" data-mdl-for="button-show-source">
Show Source
</div>
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
          
              <a  class="mdl-navigation__link" href="https://github.com/aivivn/d2l-vn">
                  <i class="fab fa-github"></i>
                  GitHub
              </a>
          
              <a  class="mdl-navigation__link" href="https://www.d2l.ai/">
                  <i class="fas fa-external-link-alt"></i>
                  English
              </a>
      </nav>
    </div>
</header><header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <span class="title-text">
                  Đắm mình vào Học Sâu
              </span>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="index_vn.html">1. Giới thiệu</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_references/zreferences.html">Tài liệu tham khảo</a></li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">
    
          <!-- Title -->
      <span class="mdl-layout-title">
          <a class="title" href="../index.html">
              <span class="title-text">
                  Đắm mình vào Học Sâu
              </span>
          </a>
      </span>
    
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="index_vn.html">1. Giới thiệu</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../chapter_references/zreferences.html">Tài liệu tham khảo</a></li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content" role="main">
        
  <div class="section" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<p>Until recently, nearly all of the computer programs that we interacted
with every day were coded by software developers from first principles.
Say that we wanted to write an application to manage an e-commerce
platform. After huddling around a whiteboard for a few hours to ponder
the problem, we would come up with the broad strokes of a working
solution that would probably look something like this: (i) users would
interact with the application through an interface running in a web
browser or mobile application (ii) our application would rely on a
commerical database engine to keep track of each user’s state and
maintain records of all historical transactions (ii) at the heart of our
application, running in parallel across many servers, the <em>business
logic</em> (you might say, the <em>brains</em>) would map out in methodical details
the appropriate action to take in every conceivable circumstance.</p>
<p>To build the <em>brains</em> of our application, we’d have to step through
every possible corner case that we anticipate encountering, devising
appropriate rules. Each time a customer clicks to add an item to their
shopping cart, we add an entry to the shopping cart database table,
associating that user’s ID with the requested product’s ID. While few
developers ever get it completely right the first time (it might take
some test runs to work out the kinks), for the most part, we could write
such a program from first principles and confidently launch it <em>before
ever seeing a real customer</em>. Our ability to design automated systems
from first principles that drive functioning products and systems, often
in novel situations, is a remarkable cognitive feat. And when you’re
able to devise solutions that work <span class="math notranslate nohighlight">\(100\%\)</span> of the time. <em>you
should not be using machine learning</em>.</p>
<p>Fortunately—for the growing community of ML scientists—many problems in
automation don’t bend so easily to human ingenuity. Imagine huddling
around the whiteboard with the smartest minds you know, but this time
you are tackling any of the following problems: * Write a program that
predicts tomorrow’s weather given geographic information, satellite
images, and a trailing window of past weather. * Write a program that
takes in a question, expressed in free-form text, and answers it
correctly. * Write a program that given an image can identify all the
people it contains, drawing outlines around each. * Write a program
that presents users with products that they are likely to enjoy but
unlikely, in the natural course of browsing, to encounter.</p>
<p>In each of these cases, even elite programmers are incapable of coding
up solutions from scratch. The reasons for this can vary. Sometimes the
program that we are looking for follows a pattern that changes over
time, and we need our programs to adapt. In other cases, the
relationship (say between pixels, and abstract categories) may be too
complicated, requiring thousands or millions of computations that are
beyond our conscious understanding (even if our eyes manage the task
effortlessly). Machine learning (ML) is the study of powerful techniques
that can <em>learn behavior</em> from <em>experience</em>. As ML algorithm accumulates
more experience, typically in the form of observational data or
interactions with an environment, their performance improves. Contrast
this with our deterministic e-commerce platform, which performs
according to the same business logic, no matter how much experience
accrues, until the developers themselves <em>learn</em> and decide that it’s
time to update the software. In this book, we will teach you the
fundamentals of machine learning, and focus in particular on deep
learning, a powerful set of techniques driving innovations in areas as
diverse as computer vision, natural language processing, healthcare, and
genomics.</p>
<div class="section" id="a-motivating-example">
<h2>A Motivating Example<a class="headerlink" href="#a-motivating-example" title="Permalink to this headline">¶</a></h2>
<p>Before we could begin writing, the authors of this book, like much of
the work force, had to become caffeinated. We hopped in the car and
started driving. Using an iPhone, Alex called out ‘Hey Siri’, awakening
the phone’s voice recognition system. Then Mu commanded ‘directions to
Blue Bottle coffee shop’. The phone quickly displayed the transcription
of his command. It also recognized that we were asking for directions
and launched the Maps application to fulfill our request. Once launched,
the Maps app identified a number of routes. Next to each route, the
phone displayed a predicted transit time. While we fabricated this story
for pedagogical convenience, it demonstrates that in the span of just a
few seconds, our everyday interactions with a smartphone can engage
several machine learning models.</p>
<p>Imagine just writing a program to respond to a <em>wake word</em> like ‘Alexa’,
‘Okay, Google’ or ‘Siri’. Try coding it up in a room by yourself with
nothing but a computer and a code editor. How would you write such a
program from first principles? Think about it… the problem is hard.
Every second, the microphone will collect roughly 44,000 samples. What
rule could map reliably from a snippet of raw audio to confident
predictions <code class="docutils literal notranslate"><span class="pre">{yes,</span> <span class="pre">no}</span></code> on whether the snippet contains the wake word?
If you’re stuck, don’t worry. We don’t know how to write such a program
from scratch either. That’s why we use ML.</p>
<p><img alt="image0" src="../_images/wake-word.svg" /></p>
<p>Here’s the trick. Often, even when we don’t know how to tell a computer
explicitly how to map from inputs to outputs, we are nonetheless capable
of performing the cognitive feat ourselves. In other words, even if you
don’t know <em>how to program a computer</em> to recognize the word ‘Alexa’,
you yourself <em>are able</em> to recognize the word ‘Alexa’. Armed with this
ability, we can collect a huge <em>dataset</em> containing examples of audio
and label those that <em>do</em> and that <em>do not</em> contain the wake word. In
the ML approach, we do not design a system <em>explicitly</em> to recognize
wake words. Instead, we define a flexible program whose behavior is
determined by a number of <em>parameters</em>. Then we use the dataset to
determine the best possible set of parameters, those that improve the
performance of our program with respect to some measure of performance
on the task of interest.</p>
<p>You can think of the parameters as knobs that we can turn, manipulating
the behavior of the program. Fixing the parameters, we call the program
a <em>model</em>. The set of all distinct programs (input-output mappings) that
we can produce just by manipulating the parameters is called a <em>family</em>
of models. And the <em>meta-program</em> that uses our dataset to choose the
parameters is called a <em>learning algorithm</em>.</p>
<p>Before we can go ahead and engage the learning algorithm, we have to
define the problem precisely, pinning down the exact nature of the
inputs and outputs, and choosing an appropriate model family. In this
case, our model receives a snippet of audio as <em>input</em>, and it generates
a selection among <code class="docutils literal notranslate"><span class="pre">{yes,</span> <span class="pre">no}</span></code> as <em>output</em>—which, if all goes according
to plan, will closely approximate whether (or not) the snippet contains
the wake word.</p>
<p>If we choose the right family of models, then there should exist one
setting of the knobs such that the model fires <code class="docutils literal notranslate"><span class="pre">yes</span></code> every time it
hears the word ‘Alexa’. Because the exact choice of the wake word is
arbitrary, we’ll probably need a model family capable, via another
setting of the knobs, of firing <code class="docutils literal notranslate"><span class="pre">yes</span></code> on the word ‘Apricot’. We expect
that the same model should apply to ‘Alexa’ recognition and ‘Apricot’
recognition because these are similar tasks. However, we might need a
different family of models entirely if we want to deal with
fundamentally different inputs or outputs, say if we wanted to map from
images to captions, or from English sentences to Chinese sentences.</p>
<p>As you might guess, if we just set all of the knobs randomly, it’s not
likely that our model will recognize ‘Alexa’, ‘Apricot’, or any other
English word. In deep learning, the <em>learning</em> is the process by which
we discover the right setting of the knobs coercing the desired
behaviour from our model.</p>
<p>The training process usually looks like this:</p>
<ol class="arabic simple">
<li><p>Start off with a randomly initialized model that can’t do anything
useful.</p></li>
<li><p>Grab some of your labeled data (e.g. audio snippets and corresponding
<code class="docutils literal notranslate"><span class="pre">{yes,no}</span></code> labels)</p></li>
<li><p>Tweak the knobs so the model sucks less with respect to those
examples</p></li>
<li><p>Repeat until the model is awesome.</p></li>
</ol>
<p><img alt="image1" src="../_images/ml-loop.svg" /></p>
<p>To summarize, rather than code up a wake word recognizer, we code up a
program that can <em>learn</em> to recognize wake words, <em>if we present it with
a large labeled dataset</em>. You can think of this act of determining a
program’s behavior by presenting it with a dataset as <em>programming with
data</em>. We can ‘program’ a cat detector by providing our machine learning
system with many examples of cats and dogs, such as the images below:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p><img alt="image2" src="../_images/cat1.png" /></p></th>
<th class="head"><p><img alt="image3" src="../_images/cat2.jpg" /></p></th>
<th class="head"><p><img alt="image4" src="../_images/dog1.jpg" /></p></th>
<th class="head"><p><img alt="image5" src="../_images/dog2.jpg" /></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>cat</p></td>
<td><p>cat</p></td>
<td><p>dog</p></td>
<td><p>dog</p></td>
</tr>
</tbody>
</table>
<p>This way the detector will eventually learn to emit a very large
positive number if it’s a cat, a very large negative number if it’s a
dog, and something closer to zero if it isn’t sure, and this barely
scratches the surface of what ML can do.</p>
<p>Deep learning is just one among many popular frameworks for solving
machine learning problems. While thus far, we’ve only talked about
machine learning broadly and not deep learning, there’s a couple points
worth sneaking in here: First, the problems that we’ve discussed thus
far: learning from raw audio signal, directly from the pixels in images,
and mapping between sentences of arbitrary lengths and across languages
are problems where deep learning excels and traditional ML tools
faltered. Deep models are <em>deep</em> in precisely the sense that they learn
many <em>layers</em> of computation. It turns out that these many-layered (or
hierarchical) models are capable of addressing low-level perceptual data
in a way that previous tools could not. In bygone days, the crucial part
of applying ML to these problems consisted of coming up with manually
engineered ways of transforming the data into some form amenable to
<em>shallow</em> models. One key advantage of deep learning is that it replaces
not only the <em>shallow</em> models at the end of traditional learning
pipelines, but also the labor-intensive feature engineering. Secondly,
by replacing much of the <em>domain-specific preprocessing</em>, deep learning
has eliminated many of the boundaries that previously separated computer
vision, speech recognition, natural language processing, medical
informatics, and other application areas, offering a unified set of
tools for tackling diverse problems.</p>
</div>
<div class="section" id="the-key-components-data-models-and-algorithms">
<h2>The Key Components: Data, Models, and Algorithms<a class="headerlink" href="#the-key-components-data-models-and-algorithms" title="Permalink to this headline">¶</a></h2>
<p>In our <em>wake-word</em> example, we described a dataset consisting of audio
snippets and binary labels gave a hand-wavy sense of how we might
<em>train</em> a model to approximate a mapping from snippets to
classifications. This sort of problem, where we try to predict a
designated unknown <em>label</em> given known <em>inputs</em> (also called <em>features</em>
or <em>covariates</em>), and examples of both is called <em>supervised learning</em>,
and it’s just one among many <em>kinds</em> of machine learning problems. In
the next section, we’ll take a deep dive into the different ML problems.
First, we’d like to shed more light on some core components that will
follow us around, no matter what kind of ML problem we take on:</p>
<ol class="arabic simple">
<li><p>The <strong>data</strong> that we can learn from</p></li>
<li><p>A <strong>model</strong> of how to transform the data</p></li>
<li><p>A <strong>loss</strong> function that quantifies the <em>badness</em> of our model</p></li>
<li><p>An <strong>algorithm</strong> to adjust the model’s parameters to minimize the
loss</p></li>
</ol>
<div class="section" id="data">
<h3>Data<a class="headerlink" href="#data" title="Permalink to this headline">¶</a></h3>
<p>It might go without saying that you cannot do data science without data.
We could lose hundreds of pages pondering the precise nature of data but
for now we’ll err on the practical side and focus on the key properties
to be concerned with. Generally we are concerned with a collection of
<em>examples</em> (also called <em>data points</em>, <em>samples</em>, or <em>instances</em>). In
order to work with data usefully, we typically need to come up with a
suitable numerical representation. Each <em>example</em> typically consists of
a collection of numerical attributes called <em>features</em> or <em>covariates</em>.</p>
<p>If we were working with image data, each individual photograph might
constitute an <em>example</em>, each represented by an ordered list of
numerical values corresponding to the brightness of each pixel. A
<span class="math notranslate nohighlight">\(200\times200\)</span> color photograph would consist of
<span class="math notranslate nohighlight">\(200\times200\times3=120000\)</span> numerical values, corresponding to
the brightness of the red, green, and blue channels corresponding to
each spatial location. In a more traditional task, we might try to
predict whether or not a patient will survive, given a standard set of
features such as age, vital signs, diagnoses, etc.</p>
<p>When every example is characterized by the same number of numerical
values, we say that the data consists of <em>fixed-length</em> vectors and we
describe the (constant) length of the vectors as the <em>dimensionality</em> of
the data. As you might imagine, fixed length can be a convenient
property. If we wanted to train a model to recognize cancer in
microscopy images, fixed-length inputs means we have one less thing to
worry about.</p>
<p>However, not all data can easily be represented as fixed length vectors.
While we might expect microscrope images to come from standard
equipment, we can’t expect images mined from the internet to all show up
in the same size. While we might imagine cropping images to a standard
size, text data resists fixed-length representations even more
stubbornly. Consider the product reviews left on e-commerce sites like
Amazon or TripAdvisor. Some are short: “it stinks!”. Others ramble for
pages. One major advantage of deep learning over traditional methods is
the comparative grace with which modern models can handle
<em>varying-length</em> data.</p>
<p>Generally, the more data we have, the easier our job becomes. When we
have more data, we can train more powerful models, and rely less heavily
on pre-conceived assumptions. The regime change from (comparatively
small) to big data is a major contributor to the success of modern deep
learning. To drive the point home, many of the most exciting models in
deep learning either don’t work without large data sets. Some others
work in the low-data regime, but no better than traditional approaches.</p>
<p>Finally it’s not enough to have lots of data and to process it cleverly.
We need the <em>right</em> data. If the data is full of mistakes, or if the
chosen features are not predictive of the target quantity of interest,
learning is going to fail. The situation is well captured by the cliché:
<em>garbage in, garbage out</em>. Moreover, poor predictive performance isn’t
the only potential consequence. In sensitive applications of machine
learning, like predictive policing, resumé screening, and risk models
used for lending, we must be especially alert to the consequences of
garbage data. One common failure mode occurs in datasets where some
groups of people are unrepresented in the training data. Imagine
applying a skin cancer recognition system in the wild that had never
seen black skin before. Failure can also occur when the data doesn’t
merely under-represent some groups, but reflects societal prejudices.
For example if past hiring decisions are used to train a predictive
model that will be used to screen resumes, then machine learning models
could inadvertently capture and automate historical injustices. Note
that this can all happen without the data scientist being complicit, or
even aware.</p>
</div>
<div class="section" id="models">
<h3>Models<a class="headerlink" href="#models" title="Permalink to this headline">¶</a></h3>
<p>Most machine learning involves <em>transforming</em> the data in some sense. We
might want to build a system that ingests photos and predicts
<em>smiley-ness</em>. Alternatively, we might want to ingest a set of sensor
readings and predict how <em>normal</em> vs <em>anomalous</em> the readings are. By
<em>model</em>, we denote the computational machinery for ingesting data of one
type, and spitting out predictions of a possibly different type. In
particular, we are interested in statistical models that can be
estimated from data. While simple models are perfectly capable of
addressing appropriately simple problems the problems that we focus on
in this book stretch the limits of classical methods. Deep learning is
differentiated from classical approaches principally by the set of
powerful models that it focuses on. These models consist of many
successive transformations of the data that are chained together top to
bottom, thus the name <em>deep learning</em>. On our way to discussing deep
neural networks, we’ll discuss some more traditional methods.</p>
</div>
<div class="section" id="objective-functions">
<h3>Objective functions<a class="headerlink" href="#objective-functions" title="Permalink to this headline">¶</a></h3>
<p>Earlier, we introduced machine learning as “learning behavior from
experience”. By <em>learning</em> here, we mean <em>improving</em> at some task over
time. But who is to say what constitutes an improvement? You might
imagine that we could propose to update our model, and some people might
disagree on whether the proposed update constitued an improvement or a
decline.</p>
<p>In order to develop a formal mathematical system of learning machines,
we need to have formal measures of how good (or bad) our models are. In
machine learning, and optimization more generally, we call these
objective functions. By convention, we usually define objective
funcitons so that <em>lower</em> is <em>better</em>. This is merely a convention. You
can take any function <span class="math notranslate nohighlight">\(f\)</span> for which higher is better, and turn it
into a new function <span class="math notranslate nohighlight">\(f'\)</span> that is qualitatively identical but for
which lower is better by setting <span class="math notranslate nohighlight">\(f' = -f\)</span>. Because lower is
better, these functions are sometimes called <em>loss functions</em> or <em>cost
functions</em>.</p>
<p>When trying to predict numerical values, the most common objective
function is squared error <span class="math notranslate nohighlight">\((y-\hat{y})^2\)</span>. For classification, the
most common objective is to minimize error rate, i.e., the fraction of
instances on which our predictions disagree with the ground truth. Some
objectives (like squared error) are easy to optimize. Others (like error
rate) are difficult to optimize directly, owing to non-differentiability
or other complications. In these cases, it’s common to optimize a
surrogate objective.</p>
<p>Typically, the loss function is defined with respect to the models
parameters and depends upon the dataset. The best values of our model’s
parameters are learned by minimizing the loss incurred on a <em>training
set</em> consisting of some number of <em>examples</em> collected for training.
However, doing well on the training data doesn’t guarantee that we will
do well on (unseen) test data. So we’ll typically want to split the
available data into two partitions: the training data (for fitting model
parameters) and the test data (which is held out for evaluation),
reporting the following two quantities:</p>
<ul class="simple">
<li><p><strong>Training Error:</strong> The error on that data on which the model was
trained. You could think of this as being like a student’s scores on
practice exams used to prepare for some real exam. Even if the
results are encouraging, that does not guarantee success on the final
exam.</p></li>
<li><p><strong>Test Error:</strong> This is the error incurred on an unseen test set.
This can deviate significantly from the training error. When a model
fails to generalize to unseen data, we say that it is <em>overfitting</em>.
In real-life terms, this is like flunking the real exam despite doing
well on practice exams.</p></li>
</ul>
</div>
<div class="section" id="optimization-algorithms">
<h3>Optimization algorithms<a class="headerlink" href="#optimization-algorithms" title="Permalink to this headline">¶</a></h3>
<p>Once we’ve got some data source and representation, a model, and a
well-defined objective function, we need an algorithm capable of
searching for the best possible parameters for minimizing the loss
function. The most popular optimization algorithms for neural networks
follow an approach called gradient descent. In short, at each step, they
check to see, for each parameter, which way the training set loss would
move if you perturbed that parameter just a small amount. They then
update the parameter in the direction that reduces the loss.</p>
</div>
</div>
<div class="section" id="kinds-of-machine-learning">
<h2>Kinds of Machine Learning<a class="headerlink" href="#kinds-of-machine-learning" title="Permalink to this headline">¶</a></h2>
<p>In the following sections, we will discuss a few types of machine
learning in some more detail. We begin with a list of <em>objectives</em>,
i.e. a list of things that machine learning can do. Note that the
objectives are complemented with a set of techniques of <em>how</em> to
accomplish them, i.e. training, types of data, etc. The list below is
really only sufficient to whet the readers’ appetite and to give us a
common language when we talk about problems. We will introduce a larger
number of such problems as we go along.</p>
<div class="section" id="supervised-learning">
<h3>Supervised learning<a class="headerlink" href="#supervised-learning" title="Permalink to this headline">¶</a></h3>
<p>Supervised learning addresses the task of predicting <em>targets</em> given
input data. The targets, also commonly called <em>labels</em>, are generally
denoted <em>y</em>. The input data points, also commonly called <em>examples</em> or
<em>instances</em>, are typically denoted <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span>. The goal is
to produce a model <span class="math notranslate nohighlight">\(f_\theta\)</span> that maps an input
<span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> to a prediction
<span class="math notranslate nohighlight">\(f_{\theta}(\boldsymbol{x})\)</span></p>
<p>To ground this description in a concrete example, if we were working in
healthcare, then we might want to predict whether or not a patient would
have a heart attack. This observation, <em>heart attack</em> or <em>no heart
attack</em>, would be our label <span class="math notranslate nohighlight">\(y\)</span>. The input data
<span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> might be vital signs such as heart rate,
diastolic and systolic blood pressure, etc.</p>
<p>The supervision comes into play because for choosing the parameters
<span class="math notranslate nohighlight">\(\theta\)</span>, we (the supervisors) provide the model with a collection
of <em>labeled examples</em> (<span class="math notranslate nohighlight">\(\boldsymbol{x}_i, y_i\)</span>), where each
example <span class="math notranslate nohighlight">\(\boldsymbol{x}_i\)</span> is matched up against its correct
label.</p>
<p>In probabilistic terms, we typically are interested in estimating the
conditional probability <span class="math notranslate nohighlight">\(P(y|x)\)</span>. While it’s just one among
several approaches to machine learning, supervised learning accounts for
the majority of machine learning in practice. Partly, that’s because
many important tasks can be described crisply as estimating the
probability of some unknown given some available evidence:</p>
<ul class="simple">
<li><p>Predict cancer vs not cancer, given a CT image.</p></li>
<li><p>Predict the correct translation in French, given a sentence in
English.</p></li>
<li><p>Predict the price of a stock next month based on this month’s
financial reporting data.</p></li>
</ul>
<p>Even with the simple description ‘predict targets from inputs’
supervised learning can take a great many forms and require a great many
modeling decisions, depending on the type, size, and the number of
inputs and outputs. For example, we use different models to process
sequences (like strings of text or time series data) and for processing
fixed-length vector representations. We’ll visit many of these problems
in depth throughout the first 9 parts of this book.</p>
<p>Put plainly, the learning process looks something like this. Grab a big
pile of example inputs, selecting them randomly. Acquire the ground
truth labels for each. Together, these inputs and corresponding labels
(the desired outputs) comprise the training set. We feed the training
dataset into a supervised learning algorithm. So here the <em>supervised
learning algorithm</em> is a function that takes as input a dataset, and
outputs another function, <em>the learned model</em>. Then, given a learned
model, we can take a new previously unseen input, and predict the
corresponding label.</p>
<p><img alt="image6" src="../_images/supervised-learning.svg" /></p>
<div class="section" id="regression">
<h4>Regression<a class="headerlink" href="#regression" title="Permalink to this headline">¶</a></h4>
<p>Perhaps the simplest supervised learning task to wrap your head around
is Regression. Consider, for example a set of data harvested from a
database of home sales. We might construct a table, where each row
corresponds to a different house, and each column corresponds to some
relevant attribute, such as the square footage of a house, the number of
bedrooms, the number of bathrooms, and the number of minutes (walking)
to the center of town. Formally, we call one row in this dataset a
<em>feature vector</em>, and the object (e.g. a house) it’s associated with an
<em>example</em>.</p>
<p>If you live in New York or San Francisco, and you are not the CEO of
Amazon, Google, Microsoft, or Facebook, the (sq. footage, no. of
bedrooms, no. of bathrooms, walking distance) feature vector for your
home might look something like: <span class="math notranslate nohighlight">\([100, 0, .5, 60]\)</span>. However, if
you live in Pittsburgh, it might look more like
<span class="math notranslate nohighlight">\([3000, 4, 3, 10]\)</span>. Feature vectors like this are essential for
all the classic machine learning problems. We’ll typically denote the
feature vector for any one example <span class="math notranslate nohighlight">\(\mathbf{x_i}\)</span> and the set of
feature vectors for all our examples <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>What makes a problem a <em>regression</em> is actually the outputs. Say that
you’re in the market for a new home, you might want to estimate the fair
market value of a house, given some features like these. The target
value, the price of sale, is a <em>real number</em>. We denote any individual
target <span class="math notranslate nohighlight">\(y_i\)</span> (corresponding to example <span class="math notranslate nohighlight">\(\mathbf{x_i}\)</span>) and
the set of all targets <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> (corresponding to all examples
X). When our targets take on arbitrary real values in some range, we
call this a regression problem. The goal of our model is to produce
predictions (guesses of the price, in our example) that closely
approximate the actual target values. We denote these predictions
<span class="math notranslate nohighlight">\(\hat{y}_i\)</span> and if the notation seems unfamiliar, then just ignore
it for now. We’ll unpack it more thoroughly in the subsequent chapters.</p>
<p>Lots of practical problems are well-described regression problems.
Predicting the rating that a user will assign to a movie is a regression
problem, and if you designed a great algorithm to accomplish this feat
in 2009, you might have won the <a class="reference external" href="https://en.wikipedia.org/wiki/Netflix_Prize">$1 million Netflix
prize</a>. Predicting the
length of stay for patients in the hospital is also a regression
problem. A good rule of thumb is that any <em>How much?</em> or <em>How many?</em>
problem should suggest regression.</p>
<ul class="simple">
<li><p>‘How many hours will this surgery take?’ - <em>regression</em></p></li>
<li><p>‘How many dogs are in this photo?’ - <em>regression</em>.</p></li>
</ul>
<p>However, if you can easily pose your problem as ‘Is this a _ ?’, then
it’s likely, classification, a different fundamental problem type that
we’ll cover next. Even if you’ve never worked with machine learning
before, you’ve probably worked through a regression problem informally.
Imagine, for example, that you had your drains repaired and that your
contractor spent <span class="math notranslate nohighlight">\(x_1=3\)</span> hours removing gunk from your sewage
pipes. Then she sent you a bill of <span class="math notranslate nohighlight">\(y_1 = \$350\)</span>. Now imagine that
your friend hired the same contractor for <span class="math notranslate nohighlight">\(x_2 = 2\)</span> hours and that
she received a bill of <span class="math notranslate nohighlight">\(y_2 = \$250\)</span>. If someone then asked you
how much to expect on their upcoming gunk-removal invoice you might make
some reasonable assumptions, such as more hours worked costs more
dollars. You might also assume that there’s some base charge and that
the contractor then charges per hour. If these assumptions held true,
then given these two data points, you could already identify the
contractor’s pricing structure: $100 per hour plus $50 to show up at
your house. If you followed that much then you already understand the
high-level idea behind linear regression (and you just implicitly
designed a linear model with bias).</p>
<p>In this case, we could produce the parameters that exactly matched the
contractor’s prices. Sometimes that’s not possible, e.g., if some of the
variance owes to some factors besides your two features. In these cases,
we’ll try to learn models that minimize the distance between our
predictions and the observed values. In most of our chapters, we’ll
focus on one of two very common losses, the <a class="reference external" href="http://mxnet.incubator.apache.org/api/python/gluon/loss.html#mxnet.gluon.loss.L1Loss">L1
loss</a>
where</p>
<div class="math notranslate nohighlight" id="equation-chapter-introduction-intro-0">
<span class="eqno">()<a class="headerlink" href="#equation-chapter-introduction-intro-0" title="Permalink to this equation">¶</a></span>\[l(y,y') = \sum_i |y_i-y_i'|\]</div>
<p>and the least mean squares loss, aka <a class="reference external" href="http://mxnet.incubator.apache.org/api/python/gluon/loss.html#mxnet.gluon.loss.L2Loss">L2
loss</a>
where</p>
<div class="math notranslate nohighlight" id="equation-chapter-introduction-intro-1">
<span class="eqno">()<a class="headerlink" href="#equation-chapter-introduction-intro-1" title="Permalink to this equation">¶</a></span>\[l(y,y') = \sum_i (y_i - y_i')^2.\]</div>
<p>As we will see later, the <span class="math notranslate nohighlight">\(L_2\)</span> loss corresponds to the assumption
that our data was corrupted by Gaussian noise, whereas the <span class="math notranslate nohighlight">\(L_1\)</span>
loss corresponds to an assumption of noise from a Laplace distribution.</p>
</div>
<div class="section" id="classification">
<h4>Classification<a class="headerlink" href="#classification" title="Permalink to this headline">¶</a></h4>
<p>While regression models are great for addressing <em>how many?</em> questions,
lots of problems don’t bend comfortably to this template. For example, a
bank wants to add check scanning to their mobile app. This would involve
the customer snapping a photo of a check with their smartphone’s camera
and the machine learning model would need to be able to automatically
understand text seen in the image. It would also need to understand
hand-written text to be even more robust. This kind of system is
referred to as optical character recognition (OCR), and the kind of
problem it solves is called a classification. It’s treated with a
distinct set of algorithms than those that are used for regression.</p>
<p>In classification, we want to look at a feature vector, like the pixel
values in an image, and then predict which category (formally called
<em>classes</em>), among some set of options, an example belongs. For
hand-written digits, we might have 10 classes, corresponding to the
digits 0 through 9. The simplest form of classification is when there
are only two classes, a problem which we call binary classification. For
example, our dataset <span class="math notranslate nohighlight">\(X\)</span> could consist of images of animals and
our <em>labels</em> <span class="math notranslate nohighlight">\(Y\)</span> might be the classes
<span class="math notranslate nohighlight">\(\mathrm{\{cat, dog\}}\)</span>. While in regression, we sought a
<em>regressor</em> to output a real value <span class="math notranslate nohighlight">\(\hat{y}\)</span>, in classification,
we seek a <em>classifier</em>, whose output <span class="math notranslate nohighlight">\(\hat{y}\)</span> is the predicted
class assignment.</p>
<p>For reasons that we’ll get into as the book gets more technical, it’s
pretty hard to optimize a model that can only output a hard categorical
assignment, e.g. either <em>cat</em> or <em>dog</em>. It’s a lot easier instead to
express the model in the language of probabilities. Given an example
<span class="math notranslate nohighlight">\(x\)</span>, the model assigns a probability <span class="math notranslate nohighlight">\(\hat{y}_k\)</span> to each
label <span class="math notranslate nohighlight">\(k\)</span>. Because these are probabilities, they need to be
positive numbers and add up to <span class="math notranslate nohighlight">\(1\)</span>. This means that we only need
<span class="math notranslate nohighlight">\(K-1\)</span> numbers to give the probabilities of <span class="math notranslate nohighlight">\(K\)</span> categories.
This is easy to see for binary classification. If there’s a 0.6 (60%)
probability that an unfair coin comes up heads, then there’s a 0.4 (40%)
probability that it comes up tails. Returning to our animal
classification example, a classifier might see an image and output the
probability that the image is a cat
<span class="math notranslate nohighlight">\(\Pr(y=\mathrm{cat}| x) = 0.9\)</span>. We can interpret this number by
saying that the classifier is 90% sure that the image depicts a cat. The
magnitude of the probability for the predicted class is one notion of
confidence. It’s not the only notion of confidence and we’ll discuss
different notions of uncertainty in more advanced chapters.</p>
<p>When we have more than two possible classes, we call the problem
<em>multiclass classification</em>. Common examples include hand-written
character recognition <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1,</span> <span class="pre">2,</span> <span class="pre">3</span> <span class="pre">...</span> <span class="pre">9,</span> <span class="pre">a,</span> <span class="pre">b,</span> <span class="pre">c,</span> <span class="pre">...]</span></code>. While we
attacked regression problems by trying to minimize the L1 or L2 loss
functions, the common loss function for classification problems is
called cross-entropy. In MXNet Gluon, the corresponding loss function
can be found
<a class="reference external" href="https://mxnet.incubator.apache.org/api/python/gluon/loss.html#mxnet.gluon.loss.SoftmaxCrossEntropyLoss">here</a>.</p>
<p>Note that the most likely class is not necessarily the one that you’re
going to use for your decision. Assume that you find this beautiful
mushroom in your backyard:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p><img alt="image7" src="../_images/death_cap.jpg" /></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Death cap - do not eat!</p></td>
</tr>
</tbody>
</table>
<p>Now, assume that you built a classifier and trained it to predict if a
mushroom is poisonous based on a photograph. Say our poison-detection
classifier outputs
<span class="math notranslate nohighlight">\(\Pr(y=\mathrm{death cap}|\mathrm{image}) = 0.2\)</span>. In other words,
the classifier is 80% confident that our mushroom <em>is not</em> a death cap.
Still, you’d have to be a fool to eat it. That’s because the certain
benefit of a delicious dinner isn’t worth a 20% risk of dying from it.
In other words, the effect of the <em>uncertain risk</em> by far outweighs the
benefit. Let’s look at this in math. Basically, we need to compute the
expected risk that we incur, i.e. we need to multiply the probability of
the outcome with the benefit (or harm) associated with it:</p>
<div class="math notranslate nohighlight" id="equation-chapter-introduction-intro-2">
<span class="eqno">()<a class="headerlink" href="#equation-chapter-introduction-intro-2" title="Permalink to this equation">¶</a></span>\[L(\mathrm{action}| x) = \mathbf{E}_{y \sim p(y| x)}[\mathrm{loss}(\mathrm{action},y)]\]</div>
<p>Hence, the loss <span class="math notranslate nohighlight">\(L\)</span> incurred by eating the mushroom is
<span class="math notranslate nohighlight">\(L(a=\mathrm{eat}| x) = 0.2 * \infty + 0.8 * 0 = \infty\)</span>, whereas
the cost of discarding it is
<span class="math notranslate nohighlight">\(L(a=\mathrm{discard}| x) = 0.2 * 0 + 0.8 * 1 = 0.8\)</span>.</p>
<p>Our caution was justified: as any mycologist would tell us, the above
mushroom actually <em>is</em> a death cap. Classification can get much more
complicated than just binary, multiclass, of even multi-label
classification. For instance, there are some variants of classification
for addressing hierarchies. Hierarchies assume that there exist some
relationships among the many classes. So not all errors are equal - we
prefer to misclassify to a related class than to a distant class.
Usually, this is referred to as <em>hierarchical classification</em>. One early
example is due to
<a class="reference external" href="https://en.wikipedia.org/wiki/Carl_Linnaeus">Linnaeus</a>, who
organized the animals in a hierarchy.</p>
<p><img alt="image8" src="../_images/sharks.png" /></p>
<p>In the case of animal classification, it might not be so bad to mistake
a poodle for a schnauzer, but our model would pay a huge penalty if it
confused a poodle for a dinosaur. Which hierarchy is relevant might
depend on how you plan to use the model. For example, rattle snakes and
garter snakes might be close on the phylogenetic tree, but mistaking a
rattler for a garter could be deadly.</p>
</div>
<div class="section" id="tagging">
<h4>Tagging<a class="headerlink" href="#tagging" title="Permalink to this headline">¶</a></h4>
<p>Some classification problems don’t fit neatly into the binary or
multiclass classification setups. For example, we could train a normal
binary classifier to distinguish cats from dogs. Given the current state
of computer vision, we can do this easily, with off-the-shelf tools.
Nonetheless, no matter how accurate our model gets, we might find
ourselves in trouble when the classifier encounters an image of the Town
Musicians of Bremen.</p>
<p><img alt="image9" src="../_images/stackedanimals.jpg" /></p>
<p>As you can see, there’s a cat in the picture, and a rooster, a dog and a
donkey, with some trees in the background. Depending on what we want to
do with our model ultimately, treating this as a binary classification
problem might not make a lot of sense. Instead, we might want to give
the model the option of saying the image depicts a cat <em>and</em> a dog <em>and</em>
a donkey <em>and</em> a rooster.</p>
<p>The problem of learning to predict classes that are <em>not mutually
exclusive</em> is called multi-label classification. Auto-tagging problems
are typically best described as multi-label classification problems.
Think of the tags people might apply to posts on a tech blog, e.g.,
‘machine learning’, ‘technology’, ‘gadgets’, ‘programming languages’,
‘linux’, ‘cloud computing’, ‘AWS’. A typical article might have 5-10
tags applied because these concepts are correlated. Posts about ‘cloud
computing’ are likely to mention ‘AWS’ and posts about ‘machine
learning’ could also deal with ‘programming languages’.</p>
<p>We also have to deal with this kind of problem when dealing with the
biomedical literature, where correctly tagging articles is important
because it allows researchers to do exhaustive reviews of the
literature. At the National Library of Medicine, a number of
professional annotators go over each article that gets indexed in PubMed
to associate it with the relevant terms from MeSH, a collection of
roughly 28k tags. This is a time-consuming process and the annotators
typically have a one year lag between archiving and tagging. Machine
learning can be used here to provide provisional tags until each article
can have a proper manual review. Indeed, for several years, the BioASQ
organization has <a class="reference external" href="http://bioasq.org/">hosted a competition</a> to do
precisely this.</p>
</div>
<div class="section" id="search-and-ranking">
<h4>Search and ranking<a class="headerlink" href="#search-and-ranking" title="Permalink to this headline">¶</a></h4>
<p>Sometimes we don’t just want to assign each example to a bucket or to a
real value. In the field of information retrieval, we want to impose a
ranking on a set of items. Take web search for example, the goal is less
to determine whether a particular page is relevant for a query, but
rather, which one of the plethora of search results should be displayed
for the user. We really care about the ordering of the relevant search
results and our learning algorithm needs to produce ordered subsets of
elements from a larger set. In other words, if we are asked to produce
the first 5 letters from the alphabet, there is a difference between
returning <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">B</span> <span class="pre">C</span> <span class="pre">D</span> <span class="pre">E</span></code> and <code class="docutils literal notranslate"><span class="pre">C</span> <span class="pre">A</span> <span class="pre">B</span> <span class="pre">E</span> <span class="pre">D</span></code>. Even if the result set is the
same, the ordering within the set matters nonetheless.</p>
<p>One possible solution to this problem is to score every element in the
set of possible sets along with a corresponding relevance score and then
to retrieve the top-rated elements.
<a class="reference external" href="https://en.wikipedia.org/wiki/PageRank">PageRank</a> is an early
example of such a relevance score. One of the peculiarities is that it
didn’t depend on the actual query. Instead, it simply helped to order
the results that contained the query terms. Nowadays search engines use
machine learning and behavioral models to obtain query-dependent
relevance scores. There are entire conferences devoted to this subject.</p>
<!-- Add / clean up--></div>
<div class="section" id="recommender-systems">
<h4>Recommender systems<a class="headerlink" href="#recommender-systems" title="Permalink to this headline">¶</a></h4>
<p>Recommender systems are another problem setting that is related to
search and ranking. The problems are similar insofar as the goal is to
display a set of relevant items to the user. The main difference is the
emphasis on <em>personalization</em> to specific users in the context of
recommender systems. For instance, for movie recommendations, the
results page for a SciFi fan and the results page for a connoisseur of
Woody Allen comedies might differ significantly.</p>
<p>Such problems occur, e.g. for movie, product or music recommendation. In
some cases, customers will provide explicit details about how much they
liked the product (e.g. Amazon product reviews). In some other cases,
they might simply provide feedback if they are dissatisfied with the
result (skipping titles on a playlist). Generally, such systems strive
to estimate some score <span class="math notranslate nohighlight">\(y_{ij}\)</span>, such as an estimated rating or
probability of purchase, given a user <span class="math notranslate nohighlight">\(u_i\)</span> and product
<span class="math notranslate nohighlight">\(p_j\)</span>.</p>
<p>Given such a model, then for any given user, we could retrieve the set
of objects with the largest scores <span class="math notranslate nohighlight">\(y_{ij}\)</span>, which are then used
as a recommendation. Production systems are considerably more advanced
and take detailed user activity and item characteristics into account
when computing such scores. The following image is an example of deep
learning books recommended by Amazon based on personalization algorithms
tuned to the author’s preferences.</p>
<p><img alt="image10" src="../_images/deeplearning_amazon.png" /></p>
</div>
<div class="section" id="sequence-learning">
<h4>Sequence Learning<a class="headerlink" href="#sequence-learning" title="Permalink to this headline">¶</a></h4>
<p>So far we’ve looked at problems where we have some fixed number of
inputs and produce a fixed number of outputs. Before we considered
predicting home prices from a fixed set of features: square footage,
number of bedrooms, number of bathrooms, walking time to downtown. We
also discussed mapping from an image (of fixed dimension), to the
predicted probabilities that it belongs to each of a fixed number of
classes, or taking a user ID and a product ID, and predicting a star
rating. In these cases, once we feed our fixed-length input into the
model to generate an output, the model immediately forgets what it just
saw.</p>
<p>This might be fine if our inputs truly all have the same dimensions and
if successive inputs truly have nothing to do with each other. But how
would we deal with video snippets? In this case, each snippet might
consist of a different number of frames. And our guess of what’s going
on in each frame might be much stronger if we take into account the
previous or succeeding frames. Same goes for language. One popular deep
learning problem is machine translation: the task of ingesting sentences
in some source language and predicting their translation in another
language.</p>
<p>These problems also occur in medicine. We might want a model to monitor
patients in the intensive care unit and to fire off alerts if their risk
of death in the next 24 hours exceeds some threshold. We definitely
wouldn’t want this model to throw away everything it knows about the
patient history each hour, and just make its predictions based on the
most recent measurements.</p>
<p>These problems are among the more exciting applications of machine
learning and they are instances of <em>sequence learning</em>. They require a
model to either ingest sequences of inputs or to emit sequences of
outputs (or both!). These latter problems are sometimes referred to as
<code class="docutils literal notranslate"><span class="pre">seq2seq</span></code> problems. Language translation is a <code class="docutils literal notranslate"><span class="pre">seq2seq</span></code> problem.
Transcribing text from spoken speech is also a <code class="docutils literal notranslate"><span class="pre">seq2seq</span></code> problem.
While it is impossible to consider all types of sequence
transformations, a number of special cases are worth mentioning:</p>
<div class="section" id="tagging-and-parsing">
<h5>Tagging and Parsing<a class="headerlink" href="#tagging-and-parsing" title="Permalink to this headline">¶</a></h5>
<p>This involves annotating a text sequence with attributes. In other
words, the number of inputs and outputs is essentially the same. For
instance, we might want to know where the verbs and subjects are.
Alternatively, we might want to know which words are the named entities.
In general, the goal is to decompose and annotate text based on
structural and grammatical assumptions to get some annotation. This
sounds more complex than it actually is. Below is a very simple example
of annotating a sentence with tags indicating which words refer to named
entities.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 10%" />
<col style="width: 17%" />
<col style="width: 8%" />
<col style="width: 25%" />
<col style="width: 13%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Tom</p></th>
<th class="head"><p>has</p></th>
<th class="head"><p>dinner</p></th>
<th class="head"><p>in</p></th>
<th class="head"><p>Washington</p></th>
<th class="head"><p>with</p></th>
<th class="head"><p>Sally.</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Ent</p></td>
<td><ul class="simple">
<li></li>
</ul>
</td>
<td><ul class="simple">
<li></li>
</ul>
</td>
<td><ul class="simple">
<li></li>
</ul>
</td>
<td><p>Ent</p></td>
<td><ul class="simple">
<li></li>
</ul>
</td>
<td><p>Ent</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="automatic-speech-recognition">
<h5>Automatic Speech Recognition<a class="headerlink" href="#automatic-speech-recognition" title="Permalink to this headline">¶</a></h5>
<p>With speech recognition, the input sequence <span class="math notranslate nohighlight">\(x\)</span> is the sound of a
speaker, and the output <span class="math notranslate nohighlight">\(y\)</span> is the textual transcript of what the
speaker said. The challenge is that there are many more audio frames
(sound is typically sampled at 8kHz or 16kHz) than text, i.e. there is
no 1:1 correspondence between audio and text, since thousands of samples
correspond to a single spoken word. These are <code class="docutils literal notranslate"><span class="pre">seq2seq</span></code> problems where
the output is much shorter than the input.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p><code class="docutils literal notranslate"><span class="pre">-D-e-e-p-</span> <span class="pre">L-ea-r-ni-ng-</span></code></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><img alt="Deep Learning" src="../_images/speech.png" /></p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="text-to-speech">
<h5>Text to Speech<a class="headerlink" href="#text-to-speech" title="Permalink to this headline">¶</a></h5>
<p>Text-to-Speech (TTS) is the inverse of speech recognition. In other
words, the input <span class="math notranslate nohighlight">\(x\)</span> is text and the output <span class="math notranslate nohighlight">\(y\)</span> is an audio
file. In this case, the output is <em>much longer</em> than the input. While it
is easy for <em>humans</em> to recognize a bad audio file, this isn’t quite so
trivial for computers.</p>
</div>
<div class="section" id="machine-translation">
<h5>Machine Translation<a class="headerlink" href="#machine-translation" title="Permalink to this headline">¶</a></h5>
<p>Unlike the case of speech recognition, where corresponding inputs and
outputs occur in the same order (after alignment), in machine
translation, order inversion can be vital. In other words, while we are
still converting one sequence into another, neither the number of inputs
and outputs nor the order of corresponding data points are assumed to be
the same. Consider the following illustrative example of the obnoxious
tendency of Germans (<em>Alex writing here</em>) to place the verbs at the end
of sentences.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 41%" />
<col style="width: 59%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>German</p></th>
<th class="head"><p>Haben Sie sich schon dieses grossartige
Lehrwerk angeschaut?</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>English</p></td>
<td><p>Did you already check out this
excellent tutorial?</p></td>
</tr>
<tr class="row-odd"><td><p>Wrong alignment</p></td>
<td><p>Did you yourself already this excellent
tutorial looked-at?</p></td>
</tr>
</tbody>
</table>
<p>A number of related problems exist. For instance, determining the order
in which a user reads a webpage is a two-dimensional layout analysis
problem. Likewise, for dialogue problems, we need to take
world-knowledge and prior state into account. This is an active area of
research.</p>
</div>
</div>
</div>
<div class="section" id="unsupervised-learning">
<h3>Unsupervised learning<a class="headerlink" href="#unsupervised-learning" title="Permalink to this headline">¶</a></h3>
<p>All the examples so far were related to <em>Supervised Learning</em>,
i.e. situations where we feed the model a bunch of examples and a bunch
of <em>corresponding target values</em>. You could think of supervised learning
as having an extremely specialized job and an extremely anal boss. The
boss stands over your shoulder and tells you exactly what to do in every
situation until you learn to map from situations to actions. Working for
such a boss sounds pretty lame. On the other hand, it’s easy to please
this boss. You just recognize the pattern as quickly as possible and
imitate their actions.</p>
<p>In a completely opposite way, it could be frustrating to work for a boss
who has no idea what they want you to do. However, if you plan to be a
data scientist, you’d better get used to it. The boss might just hand
you a giant dump of data and tell you to <em>do some data science with it!</em>
This sounds vague because it is. We call this class of problems
<em>unsupervised learning</em>, and the type and number of questions we could
ask is limited only by our creativity. We will address a number of
unsupervised learning techniques in later chapters. To whet your
appetite for now, we describe a few of the questions you might ask:</p>
<ul class="simple">
<li><p>Can we find a small number of prototypes that accurately summarize
the data? Given a set of photos, can we group them into landscape
photos, pictures of dogs, babies, cats, mountain peaks, etc.?
Likewise, given a collection of users’ browsing activity, can we
group them into users with similar behavior? This problem is
typically known as <strong>clustering</strong>.</p></li>
<li><p>Can we find a small number of parameters that accurately capture the
relevant properties of the data? The trajectories of a ball are quite
well described by velocity, diameter, and mass of the ball. Tailors
have developed a small number of parameters that describe human body
shape fairly accurately for the purpose of fitting clothes. These
problems are referred to as <strong>subspace estimation</strong> problems. If the
dependence is linear, it is called <strong>principal component analysis</strong>.</p></li>
<li><p>Is there a representation of (arbitrarily structured) objects in
Euclidean space (i.e. the space of vectors in <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>)
such that symbolic properties can be well matched? This is called
<strong>representation learning</strong> and it is used to describe entities and
their relations, such as Rome - Italy + France = Paris.</p></li>
<li><p>Is there a description of the root causes of much of the data that we
observe? For instance, if we have demographic data about house
prices, pollution, crime, location, education, salaries, etc., can we
discover how they are related simply based on empirical data? The
field of <strong>directed graphical models</strong> and <strong>causality</strong> deals with
this.</p></li>
<li><p>An important and exciting recent development is <strong>generative
adversarial networks</strong>. They are basically a procedural way of
synthesizing data. The underlying statistical mechanisms are tests to
check whether real and fake data are the same. We will devote a few
notebooks to them.</p></li>
</ul>
</div>
<div class="section" id="interacting-with-an-environment">
<h3>Interacting with an Environment<a class="headerlink" href="#interacting-with-an-environment" title="Permalink to this headline">¶</a></h3>
<p>So far, we haven’t discussed where data actually comes from, or what
actually <em>happens</em> when a machine learning model generates an output.
That’s because supervised learning and unsupervised learning do not
address these issues in a very sophisticated way. In either case, we
grab a big pile of data up front, then do our pattern recognition
without ever interacting with the environment again. Because all of the
learning takes place after the algorithm is disconnected from the
environment, this is called <em>offline learning</em>. For supervised learning,
the process looks like this:</p>
<p><img alt="image12" src="../_images/data-collection.svg" /></p>
<p>This simplicity of offline learning has its charms. The upside is we can
worry about pattern recognition in isolation without these other
problems to deal with, but the downside is that the problem formulation
is quite limiting. If you are more ambitious, or if you grew up reading
Asimov’s Robot Series, then you might imagine artificially intelligent
bots capable not only of making predictions, but of taking actions in
the world. We want to think about intelligent <em>agents</em>, not just
predictive <em>models</em>. That means we need to think about choosing
<em>actions</em>, not just making <em>predictions</em>. Moreover, unlike predictions,
actions actually impact the environment. If we want to train an
intelligent agent, we must account for the way its actions might impact
the future observations of the agent.</p>
<p>Considering the interaction with an environment opens a whole set of new
modeling questions. Does the environment:</p>
<ul class="simple">
<li><p>remember what we did previously?</p></li>
<li><p>want to help us, e.g. a user reading text into a speech recognizer?</p></li>
<li><p>want to beat us, i.e. an adversarial setting like spam filtering
(against spammers) or playing a game (vs an opponent)?</p></li>
<li><p>not care (as in most cases)?</p></li>
<li><p>have shifting dynamics (steady vs. shifting over time)?</p></li>
</ul>
<p>This last question raises the problem of <em>covariate shift</em>, (when
training and test data are different). It’s a problem that most of us
have experienced when taking exams written by a lecturer, while the
homeworks were composed by his TAs. We’ll briefly describe reinforcement
learning and adversarial learning, two settings that explicitly consider
interaction with an environment.</p>
</div>
<div class="section" id="reinforcement-learning">
<h3>Reinforcement learning<a class="headerlink" href="#reinforcement-learning" title="Permalink to this headline">¶</a></h3>
<p>If you’re interested in using machine learning to develop an agent that
interacts with an environment and takes actions, then you’re probably
going to wind up focusing on <em>reinforcement learning</em> (RL). This might
include applications to robotics, to dialogue systems, and even to
developing AI for video games. <em>Deep reinforcement learning</em> (DRL),
which applies deep neural networks to RL problems, has surged in
popularity. The breakthrough <a class="reference external" href="https://www.wired.com/2015/02/google-ai-plays-atari-like-pros/">deep Q-network that beat humans at Atari
games using only the visual
input</a>
, and the <a class="reference external" href="https://www.wired.com/2017/05/googles-alphago-trounces-humans-also-gives-boost/">AlphaGo program that dethroned the world champion at the
board game
Go</a>
are two prominent examples.</p>
<p>Reinforcement learning gives a very general statement of a problem, in
which an agent interacts with an environment over a series of <em>time
steps</em>. At each time step <span class="math notranslate nohighlight">\(t\)</span>, the agent receives some observation
<span class="math notranslate nohighlight">\(o_t\)</span> from the environment, and must choose an action <span class="math notranslate nohighlight">\(a_t\)</span>
which is then transmitted back to the environment. Finally, the agent
receives a reward <span class="math notranslate nohighlight">\(r_t\)</span> from the environment. The agent then
receives a subsequent observation, and chooses a subsequent action, and
so on. The behavior of an RL agent is governed by a <em>policy</em>. In short,
a <em>policy</em> is just a function that maps from observations (of the
environment) to actions. The goal of reinforcement learning is to
produce a good policy.</p>
<p><img alt="image13" src="../_images/rl-environment.svg" /></p>
<p>It’s hard to overstate the generality of the RL framework. For example,
we can cast any supervised learning problem as an RL problem. Say we had
a classification problem. We could create an RL agent with one <em>action</em>
corresponding to each class. We could then create an environment which
gave a reward that was exactly equal to the loss function from the
original supervised problem.</p>
<p>That being said, RL can also address many problems that supervised
learning cannot. For example, in supervised learning we always expect
that the training input comes associated with the correct label. But in
RL, we don’t assume that for each observation, the environment tells us
the optimal action. In general, we just get some reward. Moreover, the
environment may not even tell us which actions led to the reward.</p>
<p>Consider for example the game of chess. The only real reward signal
comes at the end of the game when we either win, which we might assign a
reward of 1, or when we lose, which we could assign a reward of -1. So
reinforcement learners must deal with the <em>credit assignment problem</em>.
The same goes for an employee who gets a promotion on October 11. That
promotion likely reflects a large number of well-chosen actions over the
previous year. Getting more promotions in the future requires figuring
out what actions along the way led to the promotion.</p>
<p>Reinforcement learners may also have to deal with the problem of partial
observability. That is, the current observation might not tell you
everything about your current state. Say a cleaning robot found itself
trapped in one of many identical closets in a house. Inferring the
precise location (and thus state) of the robot might require considering
its previous observations before entering the closet.</p>
<p>Finally, at any given point, reinforcement learners might know of one
good policy, but there might be many other better policies that the
agent has never tried. The reinforcement learner must constantly choose
whether to <em>exploit</em> the best currently-known strategy as a policy, or
to <em>explore</em> the space of strategies, potentially giving up some
short-run reward in exchange for knowledge.</p>
<div class="section" id="mdps-bandits-and-friends">
<h4>MDPs, bandits, and friends<a class="headerlink" href="#mdps-bandits-and-friends" title="Permalink to this headline">¶</a></h4>
<p>The general reinforcement learning problem is a very general setting.
Actions affect subsequent observations. Rewards are only observed
corresponding to the chosen actions. The environment may be either fully
or partially observed. Accounting for all this complexity at once may
ask too much of researchers. Moreover not every practical problem
exhibits all this complexity. As a result, researchers have studied a
number of <em>special cases</em> of reinforcement learning problems.</p>
<p>When the environment is fully observed, we call the RL problem a <em>Markov
Decision Process</em> (MDP). When the state does not depend on the previous
actions, we call the problem a <em>contextual bandit problem</em>. When there
is no state, just a set of available actions with initially unknown
rewards, this problem is the classic <em>multi-armed bandit problem</em>.</p>
</div>
</div>
</div>
<div class="section" id="roots">
<h2>Roots<a class="headerlink" href="#roots" title="Permalink to this headline">¶</a></h2>
<p>Although deep learning is a recent invention, humans have held the
desire to analyze data and to predict future outcomes for centuries. In
fact, much of natural science has its roots in this. For instance, the
Bernoulli distribution is named after <a class="reference external" href="https://en.wikipedia.org/wiki/Jacob_Bernoulli">Jacob Bernoulli
(1655-1705)</a>, and the
Gaussian distribution was discovered by <a class="reference external" href="https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss">Carl Friedrich Gauss
(1777-1855)</a>. He
invented for instance the least mean squares algorithm, which is still
used today for a range of problems from insurance calculations to
medical diagnostics. These tools gave rise to an experimental approach
in natural sciences - for instance, Ohm’s law relating current and
voltage in a resistor is perfectly described by a linear model.</p>
<p>Even in the middle ages mathematicians had a keen intuition of
estimates. For instance, the geometry book of <a class="reference external" href="https://www.maa.org/press/periodicals/convergence/mathematical-treasures-jacob-kobels-geometry">Jacob Köbel
(1460-1533)</a>
illustrates averaging the length of 16 adult men’s feet to obtain the
average foot length.</p>
<div class="figure align-default" id="id1">
<img alt="../_images/koebel.jpg" src="../_images/koebel.jpg" />
<p class="caption"><span class="caption-text">Estimating the length of a foot</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<p>Figure 1.1 illustrates how this estimator works. 16 adult men were asked
to line up in a row, when leaving church. Their aggregate length was
then divided by 16 to obtain an estimate for what now amounts to 1 foot.
This ‘algorithm’ was later improved to deal with misshapen feet - the 2
men with the shortest and longest feet respectively were sent away,
averaging only over the remainder. This is one of the earliest examples
of the trimmed mean estimate.</p>
<p>Statistics really took off with the collection and availability of data.
One of its titans, <a class="reference external" href="https://en.wikipedia.org/wiki/Ronald_Fisher">Ronald Fisher
(1890-1962)</a>,
contributed significantly to its theory and also its applications in
genetics. Many of his algorithms (such as Linear Discriminant Analysis)
and formulae (such as the Fisher Information Matrix) are still in
frequent use today (even the Iris dataset that he released in 1936 is
still used sometimes to illustrate machine learning algorithms).</p>
<p>A second influence for machine learning came from Information Theory
<a class="reference external" href="https://en.wikipedia.org/wiki/Claude_Shannon">(Claude Shannon,
1916-2001)</a> and the
Theory of computation via <a class="reference external" href="https://en.wikipedia.org/wiki/Alan_Turing">Alan Turing
(1912-1954)</a>. Turing posed
the question “can machines think?” in his famous paper <a class="reference external" href="https://www.jstor.org/stable/2251299">Computing
machinery and intelligence</a>
(Mind, October 1950). In what he described as the Turing test, a machine
can be considered intelligent if it is difficult for a human evaluator
to distinguish between the replies from a machine and a human being
through textual interactions. To this day, the development of
intelligent machines is changing rapidly and continuously.</p>
<p>Another influence can be found in neuroscience and psychology. After
all, humans clearly exhibit intelligent behavior. It is thus only
reasonable to ask whether one could explain and possibly reverse
engineer these insights. One of the oldest algorithms to accomplish this
was formulated by <a class="reference external" href="https://en.wikipedia.org/wiki/Donald_O._Hebb">Donald Hebb
(1904-1985)</a>.</p>
<p>In his groundbreaking book <a class="reference external" href="http://s-f-walker.org.uk/pubsebooks/pdfs/The_Organization_of_Behavior-Donald_O._Hebb.pdf">The Organization of
Behavior</a>
(John Wiley &amp; Sons, 1949) he posited that neurons learn by positive
reinforcement. This became known as the Hebbian learning rule. It is the
prototype of Rosenblatt’s perceptron learning algorithm and it laid the
foundations of many stochastic gradient descent algorithms that underpin
deep learning today: reinforce desirable behavior and diminish
undesirable behavior to obtain good weights in a neural network.</p>
<p>Biological inspiration is what gave Neural Networks its name. For over a
century (dating back to the models of Alexander Bain, 1873 and James
Sherrington, 1890) researchers have tried to assemble computational
circuits that resemble networks of interacting neurons. Over time the
interpretation of biology became more loose but the name stuck. At its
heart lie a few key principles that can be found in most networks today:</p>
<ul class="simple">
<li><p>The alternation of linear and nonlinear processing units, often
referred to as ‘layers’.</p></li>
<li><p>The use of the chain rule (aka backpropagation) for adjusting
parameters in the entire network at once.</p></li>
</ul>
<p>After initial rapid progress, research in Neural Networks languished
from around 1995 until 2005. This was due to a number of reasons.
Training a network is computationally very expensive. While RAM was
plentiful at the end of the past century, computational power was
scarce. Secondly, datasets were relatively small. In fact, Fisher’s
‘Iris dataset’ from 1932 was a popular tool for testing the efficacy of
algorithms. MNIST with its 60,000 handwritten digits was considered
huge.</p>
<p>Given the scarcity of data and computation, strong statistical tools
such as Kernel Methods, Decision Trees and Graphical Models proved
empirically superior. Unlike Neural Networks they did not require weeks
to train and provided predictable results with strong theoretical
guarantees.</p>
</div>
<div class="section" id="the-road-to-deep-learning">
<h2>The Road to Deep Learning<a class="headerlink" href="#the-road-to-deep-learning" title="Permalink to this headline">¶</a></h2>
<p>Much of this changed with the ready availability of large amounts of
data, due to the World Wide Web, the advent of companies serving
hundreds of millions of users online, a dissemination of cheap, high
quality sensors, cheap data storage (Kryder’s law), and cheap
computation (Moore’s law), in particular in the form of GPUs, originally
engineered for computer gaming. Suddenly algorithms and models that
seemed computationally infeasible became relevant (and vice versa). This
is best illustrated in the table below:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Decade</p></th>
<th class="head"><p>Dataset</p></th>
<th class="head"><p>Memory</p></th>
<th class="head"><p>Floating Point
Calculations
per Second</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1970</p></td>
<td><p>100 (Iris)</p></td>
<td><p>1 KB</p></td>
<td><p>100 KF (Intel
8080)</p></td>
</tr>
<tr class="row-odd"><td><p>1980</p></td>
<td><p>1 K (House
prices in
Boston)</p></td>
<td><p>100 KB</p></td>
<td><p>1 MF (Intel
80186)</p></td>
</tr>
<tr class="row-even"><td><p>1990</p></td>
<td><p>10 K (optical
character
recognition)</p></td>
<td><p>10 MB</p></td>
<td><p>10 MF (Intel
80486)</p></td>
</tr>
<tr class="row-odd"><td><p>2000</p></td>
<td><p>10 M (web
pages)</p></td>
<td><p>100 MB</p></td>
<td><p>1 GF (Intel
Core)</p></td>
</tr>
<tr class="row-even"><td><p>2010</p></td>
<td><p>10 G
(advertising)</p></td>
<td><p>1 GB</p></td>
<td><p>1 TF (Nvidia
C2050)</p></td>
</tr>
<tr class="row-odd"><td><p>2020</p></td>
<td><p>1 T (social
network)</p></td>
<td><p>100 GB</p></td>
<td><p>1 PF (Nvidia
DGX-2)</p></td>
</tr>
</tbody>
</table>
<p>It is quite evident that RAM has not kept pace with the growth in data.
At the same time, the increase in computational power has outpaced that
of the data available. This means that statistical models needed to
become more memory efficient (this is typically achieved by adding
nonlinearities) while simultaneously being able to spend more time on
optimizing these parameters, due to an increased compute budget.
Consequently the sweet spot in machine learning and statistics moved
from (generalized) linear models and kernel methods to deep networks.
This is also one of the reasons why many of the mainstays of deep
learning, such as Multilayer Perceptrons (e.g. McCulloch &amp; Pitts, 1943),
Convolutional Neural Networks (Le Cun, 1992), Long Short Term Memory
(Hochreiter &amp; Schmidhuber, 1997), Q-Learning (Watkins, 1989), were
essentially ‘rediscovered’ in the past decade, after laying dormant for
considerable time.</p>
<p>The recent progress in statistical models, applications, and algorithms,
has sometimes been likened to the Cambrian Explosion: a moment of rapid
progress in the evolution of species. Indeed, the state of the art is
not just a mere consequence of available resources, applied to decades
old algorithms. Note that the list below barely scratches the surface of
the ideas that have helped researchers achieve tremendous progress over
the past decade.</p>
<ul class="simple">
<li><p>Novel methods for capacity control, such as Dropout [3] allowed for
training of relatively large networks without the danger of
overfitting, i.e. without the danger of merely memorizing large parts
of the training data. This was achieved by applying noise injection
[4] throughout the network, replacing weights by random variables for
training purposes.</p></li>
<li><p>Attention mechanisms solved a second problem that had plagued
statistics for over a century: how to increase the memory and
complexity of a system without increasing the number of learnable
parameters. [5] found an elegant solution by using what can only be
viewed as a learnable pointer structure. That is, rather than having
to remember an entire sentence, e.g. for machine translation in a
fixed-dimensional representation, all that needed to be stored was a
pointer to the intermediate state of the translation process. This
allowed for significantly increased accuracy for long sentences,
since the model no longer needed to remember the entire sentence
before beginning to generate sentences.</p></li>
<li><p>Multi-stage designs, e.g. via the Memory Networks [6] and the Neural
Programmer-Interpreter [7] allowed statistical modelers to describe
iterative approaches to reasoning. These tools allow for an internal
state of the deep network to be modified repeatedly, thus carrying
out subsequent steps in a chain of reasoning, similar to how a
processor can modify memory for a computation.</p></li>
<li><p>Another key development was the invention of Generative Adversarial
Networks [8]. Traditionally statistical methods for density
estimation and generative models focused on finding proper
probability distributions and (often approximate) algorithms for
sampling from them. As a result, these algorithms were largely
limited by the lack of flexibility inherent in the statistical
models. The crucial innovation in GANs was to replace the sampler by
an arbitrary algorithm with differentiable parameters. These are then
adjusted in such a way that the discriminator (effectively a
two-sample test) cannot distinguish fake from real data. Through the
ability to use arbitrary algorithms to generate data it opened up
density estimation to a wide variety of techniques. Examples of
galloping Zebras [9] and of fake celebrity faces [10] are both
testimony to this progress.</p></li>
<li><p>In many cases a single GPU is insufficient to process the large
amounts of data available for training. Over the past decade the
ability to build parallel distributed training algorithms has
improved significantly. One of the key challenges in designing
scalable algorithms is that the workhorse of deep learning
optimization, stochastic gradient descent, relies on relatively small
minibatches of data to be processed. At the same time, small batches
limit the efficiency of GPUs. Hence, training on 1024 GPUs with a
minibatch size of, say 32 images per batch amounts to an aggregate
minibatch of 32k images. Recent work, first by Li [11], and
subsequently by You et al. [12] and Jia et al. [13] pushed the size
up to 64k observations, reducing training time for ResNet50 on
ImageNet to less than 7 minutes. For comparison - initially training
times were measured in the order of days.</p></li>
<li><p>The ability to parallelize computation has also contributed quite
crucially to progress in reinforcement learning, at least whenever
simulation is an option. This has led to significant progress in
computers achieving superhuman performance in Go, Atari games,
Starcraft, and in physics simulations (e.g. using MuJoCo). See
e.g. Silver et al. [18] for a description of how to achieve this in
AlphaGo. In a nutshell, reinforcement learning works best if plenty
of (state, action, reward) triples are available, i.e. whenever it is
possible to try out lots of things to learn how they relate to each
other. Simulation provides such an avenue.</p></li>
<li><p>Deep Learning frameworks have played a crucial role in disseminating
ideas. The first generation of frameworks allowing for easy modeling
encompassed <a class="reference external" href="https://github.com/BVLC/caffe">Caffe</a>,
<a class="reference external" href="https://github.com/torch">Torch</a>, and
<a class="reference external" href="https://github.com/Theano/Theano">Theano</a>. Many seminal papers
were written using these tools. By now they have been superseded by
<a class="reference external" href="https://github.com/tensorflow/tensorflow">TensorFlow</a>, often used
via its high level API
<a class="reference external" href="https://github.com/keras-team/keras">Keras</a>,
<a class="reference external" href="https://github.com/Microsoft/CNTK">CNTK</a>, <a class="reference external" href="https://github.com/caffe2/caffe2">Caffe
2</a>, and <a class="reference external" href="https://github.com/apache/incubator-mxnet">Apache
MxNet</a>. The third
generation of tools, namely imperative tools for deep learning, was
arguably spearheaded by
<a class="reference external" href="https://github.com/chainer/chainer">Chainer</a>, which used a syntax
similar to Python NumPy to describe models. This idea was adopted by
<a class="reference external" href="https://github.com/pytorch/pytorch">PyTorch</a> and the <a class="reference external" href="https://github.com/apache/incubator-mxnet">Gluon
API</a> of MxNet. It is
the latter that this course uses to teach Deep Learning.</p></li>
</ul>
<p>The division of labor between systems researchers building better tools
for training and statistical modelers building better networks has
greatly simplified things. For instance, training a linear logistic
regression model used to be a nontrivial homework problem, worthy to
give to new Machine Learning PhD students at Carnegie Mellon University
in 2014. By now, this task can be accomplished with less than 10 lines
of code, putting it firmly into the grasp of programmers.</p>
</div>
<div class="section" id="success-stories">
<h2>Success Stories<a class="headerlink" href="#success-stories" title="Permalink to this headline">¶</a></h2>
<p>Artificial Intelligence has a long history of delivering results that
would be difficult to accomplish otherwise. For instance, mail is sorted
using optical character recognition. These systems have been deployed
since the 90s (this is, after all, the source of the famous MNIST and
USPS sets of handwritten digits). The same applies to reading checks for
bank deposits and scoring creditworthiness of applicants. Financial
transactions are checked for fraud automatically. This forms the
backbone of many e-commerce payment systems, such as PayPal, Stripe,
AliPay, WeChat, Apple, Visa, MasterCard. Computer programs for chess
have been competitive for decades. Machine learning feeds search,
recommendation, personalization and ranking on the internet. In other
words, artificial intelligence and machine learning are pervasive,
albeit often hidden from sight.</p>
<p>It is only recently that AI has been in the limelight, mostly due to
solutions to problems that were considered intractable previously.</p>
<ul class="simple">
<li><p>Intelligent assistants, such as Apple’s Siri, Amazon’s Alexa, or
Google’s assistant are able to answer spoken questions with a
reasonable degree of accuracy. This includes menial tasks such as
turning on light switches (a boon to the disabled) up to making
barber’s appointments and offering phone support dialog. This is
likely the most noticeable sign that AI is affecting our lives.</p></li>
<li><p>A key ingredient in digital assistants is the ability to recognize
speech accurately. Gradually the accuracy of such systems has
increased to the point where they reach human parity [14] for certain
applications.</p></li>
<li><p>Object recognition likewise has come a long way. Estimating the
object in a picture was a fairly challenging task in 2010. On the
ImageNet benchmark Lin et al. [15] achieved a top-5 error rate of
28%. By 2017 Hu et al. [16] reduced this error rate to 2.25%.
Similarly stunning results have been achieved for identifying birds,
or diagnosing skin cancer.</p></li>
<li><p>Games used to be a bastion of human intelligence. Starting from
TDGammon [23], a program for playing Backgammon using temporal
difference (TD) reinforcement learning, algorithmic and computational
progress has led to algorithms for a wide range of applications.
Unlike Backgammon, chess has a much more complex state space and set
of actions. DeepBlue beat Gary Kasparov, Campbell et al. [17], using
massive parallelism, special purpose hardware and efficient search
through the game tree. Go is more difficult still, due to its huge
state space. AlphaGo reached human parity in 2015, Silver et al. [18]
using Deep Learning combined with Monte Carlo tree sampling. The
challenge in Poker was that the state space is large and it is not
fully observed (we don’t know the opponents’ cards). Libratus
exceeded human performance in Poker using efficiently structured
strategies; Brown and Sandholm [19]. This illustrates the impressive
progress in games and the fact that advanced algorithms played a
crucial part in them.</p></li>
<li><p>Another indication of progress in AI is the advent of self-driving
cars and trucks. While full autonomy is not quite within reach yet,
excellent progress has been made in this direction, with companies
such as <a class="reference external" href="https://www.momenta.ai/en">Momenta</a>,
<a class="reference external" href="http://www.tesla.com">Tesla</a>, <a class="reference external" href="http://www.nvidia.com">NVIDIA</a>,
<a class="reference external" href="http://www.mobileye.com">MobilEye</a> and
<a class="reference external" href="http://www.waymo.com">Waymo</a> shipping products that enable at
least partial autonomy. What makes full autonomy so challenging is
that proper driving requires the ability to perceive, to reason and
to incorporate rules into a system. At present, Deep Learning is used
primarily in the computer vision aspect of these problems. The rest
is heavily tuned by engineers.</p></li>
</ul>
<p>Again, the above list barely scratches the surface of what is considered
intelligent and where machine learning has led to impressive progress in
a field. For instance, robotics, logistics, computational biology,
particle physics and astronomy owe some of their most impressive recent
advances at least in parts to machine learning. ML is thus becoming a
ubiquitous tool for engineers and scientists.</p>
<p>Frequently the question of the AI apocalypse, or the AI singularity has
been raised in non-technical articles on AI. The fear is that somehow
machine learning systems will become sentient and decide independently
from their programmers (and masters) about things that directly affect
the livelihood of humans. To some extent AI already affects the
livelihood of humans in an immediate way - creditworthiness is assessed
automatically, autopilots mostly navigate cars safely, decisions about
whether to grant bail use statistical data as input. More frivolously,
we can ask Alexa to switch on the coffee machine and she will happily
oblige, provided that the appliance is internet enabled.</p>
<p>Fortunately we are far from a sentient AI system that is ready to
enslave its human creators (or burn their coffee). Firstly, AI systems
are engineered, trained and deployed in a specific, goal oriented
manner. While their behavior might give the illusion of general
intelligence, it is a combination of rules, heuristics and statistical
models that underlie the design. Second, at present tools for general
Artificial Intelligence simply do not exist that are able to improve
themselves, reason about themselves, and that are able to modify, extend
and improve their own architecture while trying to solve general tasks.</p>
<p>A much more realistic concern is how AI is being used in our daily
lives. It is likely that many menial tasks fulfilled by truck drivers
and shop assistants can and will be automated. Farm robots will likely
reduce the cost for organic farming but they will also automate
harvesting operations. This phase of the industrial revolution will have
profound consequences on large swaths of society (truck drivers and shop
assistants are some of the most common jobs in many states).
Furthermore, statistical models, when applied without care can lead to
racial, gender or age bias. It is important to ensure that these
algorithms are used with great care. This is a much bigger concern than
to worry about a potentially malevolent superintelligence intent on
destroying humanity.</p>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Machine learning studies how computer systems can use data to improve
performance. It combines ideas from statistics, data mining,
artificial intelligence and optimization. Often it is used as a means
of implementing artificially intelligent solutions.</p></li>
<li><p>As a class of machine learning, representational learning focuses on
how to automatically find the appropriate way to represent data. This
is often accomplished by a progression of learned transformations.</p></li>
<li><p>Much of the recent progress has been triggered by an abundance of
data arising from cheap sensors and internet scale applications, and
by significant progress in computation, mostly through GPUs.</p></li>
<li><p>Whole system optimization is a key component in obtaining good
performance. The availability of efficient deep learning frameworks
has made design and implementation of this significantly easier.</p></li>
</ul>
</div>
<div class="section" id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p>Which parts of code that you are currently writing could be
‘learned’, i.e. improved by learning and automatically determining
design choices that are made in your code? Does your code include
heuristic design choices?</p></li>
<li><p>Which problems that you encounter have many examples for how to solve
them, yet no specific way to automate them? These may be prime
candidates for using Deep Learning.</p></li>
<li><p>Viewing the development of Artificial Intelligence as a new
industrial revolution, what is the relationship between algorithms
and data? Is it similar to steam engines and coal (what is the
fundamental difference)?</p></li>
<li><p>Where else can you apply the end-to-end training approach? Physics?
Engineering? Econometrics?</p></li>
</ol>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p>[1] Turing, A. M. (1950). Computing machinery and intelligence. Mind,
59(236), 433.</p>
<p>[2] Hebb, D. O. (1949). The organization of behavior; a
neuropsychological theory. A Wiley Book in Clinical Psychology. 62-78.</p>
<p>[3] Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., &amp;
Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural
networks from overfitting. The Journal of Machine Learning Research,
15(1), 1929-1958.</p>
<p>[4] Bishop, C. M. (1995). Training with noise is equivalent to Tikhonov
regularization. Neural computation, 7(1), 108-116.</p>
<p>[5] Bahdanau, D., Cho, K., &amp; Bengio, Y. (2014). Neural machine
translation by jointly learning to align and translate. arXiv preprint
arXiv:1409.0473.</p>
<p>[6] Sukhbaatar, S., Weston, J., &amp; Fergus, R. (2015). End-to-end memory
networks. In Advances in neural information processing systems
(pp. 2440-2448).</p>
<p>[7] Reed, S., &amp; De Freitas, N. (2015). Neural programmer-interpreters.
arXiv preprint arXiv:1511.06279.</p>
<p>[8] Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley,
D., Ozair, S., … &amp; Bengio, Y. (2014). Generative adversarial nets. In
Advances in neural information processing systems (pp. 2672-2680).</p>
<p>[9] Zhu, J. Y., Park, T., Isola, P., &amp; Efros, A. A. (2017). Unpaired
image-to-image translation using cycle-consistent adversarial networks.
arXiv preprint.</p>
<p>[10] Karras, T., Aila, T., Laine, S., &amp; Lehtinen, J. (2017). Progressive
growing of gans for improved quality, stability, and variation. arXiv
preprint arXiv:1710.10196.</p>
<p>[11] Li, M. (2017). Scaling Distributed Machine Learning with System and
Algorithm Co-design (Doctoral dissertation, PhD thesis, Intel).</p>
<p>[12] You, Y., Gitman, I., &amp; Ginsburg, B. Large batch training of
convolutional networks. ArXiv e-prints.</p>
<p>[13] Jia, X., Song, S., He, W., Wang, Y., Rong, H., Zhou, F., … &amp; Chen,
T. (2018). Highly Scalable Deep Learning Training System with
Mixed-Precision: Training ImageNet in Four Minutes. arXiv preprint
arXiv:1807.11205.</p>
<p>[14] Xiong, W., Droppo, J., Huang, X., Seide, F., Seltzer, M., Stolcke,
A., … &amp; Zweig, G. (2017, March). The Microsoft 2016 conversational
speech recognition system. In Acoustics, Speech and Signal Processing
(ICASSP), 2017 IEEE International Conference on (pp. 5255-5259). IEEE.</p>
<p>[15] Lin, Y., Lv, F., Zhu, S., Yang, M., Cour, T., Yu, K., … &amp; Huang, T.
(2010). Imagenet classification: fast descriptor coding and large-scale
svm training. Large scale visual recognition challenge.</p>
<p>[16] Hu, J., Shen, L., &amp; Sun, G. (2017). Squeeze-and-excitation
networks. arXiv preprint arXiv:1709.01507, 7.</p>
<p>[17] Campbell, M., Hoane Jr, A. J., &amp; Hsu, F. H. (2002). Deep blue.
Artificial intelligence, 134 (1-2), 57-83.</p>
<p>[18] Silver, D., Huang, A., Maddison, C. J., Guez, A., Sifre, L., Van
Den Driessche, G., … &amp; Dieleman, S. (2016). Mastering the game of Go
with deep neural networks and tree search. Nature, 529 (7587), 484.</p>
<p>[19] Brown, N., &amp; Sandholm, T. (2017, August). Libratus: The superhuman
ai for no-limit poker. In Proceedings of the Twenty-Sixth International
Joint Conference on Artificial Intelligence.</p>
<p>[20] Canny, J. (1986). A computational approach to edge detection. IEEE
Transactions on pattern analysis and machine intelligence, (6), 679-698.</p>
<p>[21] Lowe, D. G. (2004). Distinctive image features from scale-invariant
keypoints. International journal of computer vision, 60(2), 91-110.</p>
<p>[22] Salton, G., &amp; McGill, M. J. (1986). Introduction to modern
information retrieval.</p>
<p>[23] Tesauro, G. (1995), Transactions of the ACM, (38) 3, 58-68</p>
</div>
<div class="section" id="scan-the-qr-code-to-discuss">
<h2>Scan the QR Code to <a class="reference external" href="https://discuss.mxnet.io/t/2310">Discuss</a><a class="headerlink" href="#scan-the-qr-code-to-discuss" title="Permalink to this headline">¶</a></h2>
<p><img alt="image14" src="chapter_introduction/../img/qr_intro.svg" /></p>
</div>
</div>


        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
<div class="localtoc">
    <p class="caption">
      <span class="caption-text">Table Of Contents</span>
    </p>
    <ul>
<li><a class="reference internal" href="#">Introduction</a><ul>
<li><a class="reference internal" href="#a-motivating-example">A Motivating Example</a></li>
<li><a class="reference internal" href="#the-key-components-data-models-and-algorithms">The Key Components: Data, Models, and Algorithms</a><ul>
<li><a class="reference internal" href="#data">Data</a></li>
<li><a class="reference internal" href="#models">Models</a></li>
<li><a class="reference internal" href="#objective-functions">Objective functions</a></li>
<li><a class="reference internal" href="#optimization-algorithms">Optimization algorithms</a></li>
</ul>
</li>
<li><a class="reference internal" href="#kinds-of-machine-learning">Kinds of Machine Learning</a><ul>
<li><a class="reference internal" href="#supervised-learning">Supervised learning</a><ul>
<li><a class="reference internal" href="#regression">Regression</a></li>
<li><a class="reference internal" href="#classification">Classification</a></li>
<li><a class="reference internal" href="#tagging">Tagging</a></li>
<li><a class="reference internal" href="#search-and-ranking">Search and ranking</a></li>
<li><a class="reference internal" href="#recommender-systems">Recommender systems</a></li>
<li><a class="reference internal" href="#sequence-learning">Sequence Learning</a><ul>
<li><a class="reference internal" href="#tagging-and-parsing">Tagging and Parsing</a></li>
<li><a class="reference internal" href="#automatic-speech-recognition">Automatic Speech Recognition</a></li>
<li><a class="reference internal" href="#text-to-speech">Text to Speech</a></li>
<li><a class="reference internal" href="#machine-translation">Machine Translation</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#unsupervised-learning">Unsupervised learning</a></li>
<li><a class="reference internal" href="#interacting-with-an-environment">Interacting with an Environment</a></li>
<li><a class="reference internal" href="#reinforcement-learning">Reinforcement learning</a><ul>
<li><a class="reference internal" href="#mdps-bandits-and-friends">MDPs, bandits, and friends</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#roots">Roots</a></li>
<li><a class="reference internal" href="#the-road-to-deep-learning">The Road to Deep Learning</a></li>
<li><a class="reference internal" href="#success-stories">Success Stories</a></li>
<li><a class="reference internal" href="#summary">Summary</a></li>
<li><a class="reference internal" href="#exercises">Exercises</a></li>
<li><a class="reference internal" href="#references">References</a></li>
<li><a class="reference internal" href="#scan-the-qr-code-to-discuss">Scan the QR Code to Discuss</a></li>
</ul>
</li>
</ul>

</div>
            </div>
        </div>

      <div class="clearer"></div>
    </div><div class="pagenation">
  </div>
        
        </main>
    </div>
  </body>
</html>